"""
The internal model alias:
``v6-relPosAttDef-noBias-aedLoss-bhv20-11gb-f32-bs15k-accgrad1-mgpu4-pavg100-wd1e_2-lrlin1e_5_295k-featBN-speedpertV2-spm10k-bpeSample001``

Checkpoint also here: https://huggingface.co/rwth-i6/2024-zeyer-ctc-librispeech-spm10k

This file here is intended to serve as an example for how to use the model.
You can copy the code here and adapt it to your needs.
"""

from __future__ import annotations

from typing import Dict, Any, Optional, Sequence, Tuple
import os
import torch

from returnn.tensor import Tensor, Dim
import returnn.frontend as rf
from returnn.frontend.encoder.conformer import ConformerEncoder, ConformerEncoderLayer, ConformerConvSubsample
from returnn.torch.frontend.bridge import rf_module_to_pt_module
from returnn.datasets.util.vocabulary import Vocabulary

# EDIT this to the path where the model / SPM vocab is stored, e.g. HF repo dir
_data_dirs = [os.getcwd()]


def _get_vocab_file() -> str:
    for data_dir in _data_dirs:
        if os.path.exists(f"{data_dir}/spm.vocab"):
            return f"{data_dir}/spm.vocab"
        if os.path.exists(f"{data_dir}/deps/spm.vocab"):
            return f"{data_dir}/deps/spm.vocab"
    raise FileNotFoundError(f"Could not find spm.vocab. Edit _data_dirs. Searched in {_data_dirs}")


def _get_model_ckpt_file() -> str:
    for data_dir in _data_dirs:
        if os.path.exists(f"{data_dir}/epoch.500.pt"):
            return f"{data_dir}/epoch.500.pt"
        if os.path.exists(f"{data_dir}/data/epoch.500.pt"):
            return f"{data_dir}/data/epoch.500.pt"
    raise FileNotFoundError(f"Could not find epoch.500.pt. Edit _data_dirs. Searched in {_data_dirs}")


model_config = {
    "behavior_version": 21,
    "backend": "torch",
    "enc_conformer_layer": rf.build_dict(
        rf.encoder.conformer.ConformerEncoderLayer,
        ff=rf.build_dict(
            rf.encoder.conformer.ConformerPositionwiseFeedForward,
            activation=rf.build_dict(rf.relu_square),
            with_bias=False,
        ),
        num_heads=8,
    ),
    "feature_batch_norm": True,
}

vocab_name = "spm10k"
_vocab_size = 10_240  # See i6_experiments.users.zeyer.datasets.librispeech._get_spm_vocab
_vocab_opts = dict(unknown_label="<unk>", bos_label="<s>", eos_label="</s>")

output_blank_label = "<blank>"
_ctc_model_def_blank_idx: int = -1

# The model gets raw features (16khz) and does feature extraction internally.
_log_mel_feature_dim = 80


def _demo():
    import argparse
    import soundfile  # pip install pysoundfile
    import numpy as np
    from returnn.util import better_exchook
    from returnn.util.basic import BehaviorVersion

    better_exchook.install()

    try:
        import lovely_tensors

        lovely_tensors.monkey_patch()
    except ImportError:
        pass  # ignore

    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument("soundfile", help="Input audio file, e.g. wav, ogg, flac")
    arg_parser.add_argument("--device", default="auto", help="Device, e.g. 'cuda', 'cpu', 'auto'")
    arg_parser.add_argument("--data-dir", help="where to find the model/vocab")
    args = arg_parser.parse_args()

    BehaviorVersion.set_min_behavior_version(21)
    rf.select_backend_torch()

    if args.device == "auto":
        dev_s = "cuda" if torch.cuda.is_available() else "cpu"
    else:
        dev_s = args.device
    dev = torch.device(dev_s)

    if args.data_dir:
        _data_dirs.clear()
        _data_dirs.append(args.data_dir)

    model = create_model(device=dev)

    print(f"Loading soundfile {args.soundfile}...")
    data, samplerate = soundfile.read(args.soundfile)
    assert samplerate == 16_000, f"Expected 16khz, got {samplerate}"
    assert isinstance(data, np.ndarray)
    data = data.astype(np.float32)

    # Add some batch dim. Not really necessary here, but just to show how it works.
    data = data[None, :]  # [batch_dim,audio_spatial_dim]
    assert data.ndim == 2
    data_pt = torch.tensor(data).to(dev)
    batch_dim = Dim(1, name="batch")
    audio_seq_lens = rf.convert_to_tensor([data.shape[1]], dims=[batch_dim], dtype="int32")
    audio_spatial_dim = Dim(audio_seq_lens, name="time")
    source = rf.convert_to_tensor(data_pt, dims=[batch_dim, audio_spatial_dim])  # [batch_dim,audio_spatial_dim]

    rf.set_default_device(dev_s)

    logits, enc, enc_spatial_dim = model(
        source, in_spatial_dim=audio_spatial_dim
    )  # [batch_dim,enc_spatial_dim,model_dim|wb_target_dim]
    labels = rf.reduce_argmax(logits, axis=model.wb_target_dim)
    labels = rf.cast(labels, "int32")

    labels_shifted = rf.shift_right(labels, axis=enc_spatial_dim, pad_value=model.blank_idx)
    mask_repeat = labels != labels_shifted
    labels, labels_spatial_dim = rf.masked_select(
        labels, mask=(labels != model.blank_idx) & mask_repeat, dims=[enc_spatial_dim]
    )  # {batch_dim,labels_spatial_dim}
    labels_raw = labels.copy_compatible_to_dims_raw([batch_dim, labels_spatial_dim]).cpu()
    labels_seq_lens = labels_spatial_dim.get_size_tensor().copy_compatible_to_dims_raw([batch_dim])

    # batch_size=1 here, so simplify the code:
    labels_raw = labels_raw[0, : labels_seq_lens[0]]  # [labels_spatial_dim]
    labels_s = model.target_dim.vocab.get_seq_labels(labels_raw)
    print("Recognized label sequence:", labels_s)
    print("SPM-to-words:", labels_s.replace(" ", "").replace("▁", " ").strip())


def create_model(*, load_params: bool = True, device: Optional[torch.device] = None) -> Model:
    """
    Create model.

    Adapted from :func:`i6_experiments.users.zeyer.experiments.exp2024_04_23_baselines.ctc.ctc_model_def`.

    :param load_params: if True, load params from the checkpoint. Otherwise, keep randomly initialized.
    :param device:
    :return: model. See :func:`Model.__call__` for main usage.
    """
    from returnn.config import get_global_config
    from returnn.util.basic import BehaviorVersion

    BehaviorVersion.set_min_behavior_version(21)
    rf.select_backend_torch()

    config = get_global_config(auto_create=True)
    config.update(model_config)

    target_dim = Dim(_vocab_size, name="vocab")
    target_dim.vocab = Vocabulary(_get_vocab_file(), **_vocab_opts)

    enc_aux_logits = config.typed_value("aux_loss_layers")
    num_enc_layers = config.int("num_enc_layers", 12)
    # real input is raw audio, internally it does logmel
    in_dim = Dim(name="logmel", dimension=_log_mel_feature_dim, kind=Dim.Types.Feature)

    enc_input_layer = config.typed_value("enc_input_layer", None)
    conv_norm = config.typed_value("conv_norm", None)
    enc_conformer_layer = config.typed_value("enc_conformer_layer", None)
    assert enc_conformer_layer
    assert not conv_norm, "set only enc_conformer_layer or conv_norm, not both"
    assert isinstance(enc_conformer_layer, dict) and "class" in enc_conformer_layer
    enc_other_opts = config.typed_value("enc_other_opts", None)

    blank_idx = _ctc_model_def_blank_idx
    if blank_idx < 0:
        blank_idx = target_dim.dimension + 1 + blank_idx

    model = Model(
        in_dim=in_dim,
        enc_build_dict=config.typed_value("enc_build_dict", None),  # alternative more generic/flexible way
        num_enc_layers=num_enc_layers,
        enc_model_dim=Dim(name="enc", dimension=512, kind=Dim.Types.Feature),
        enc_input_layer=enc_input_layer,
        enc_conformer_layer=enc_conformer_layer,
        enc_other_opts=enc_other_opts,
        target_dim=target_dim,
        blank_idx=blank_idx,
        enc_aux_logits=enc_aux_logits or (),
    )

    pt_model: torch.nn.Module = rf_module_to_pt_module(model)
    print("Model:", pt_model)
    num_params = sum([parameter.numel() for parameter in pt_model.parameters()])
    print(f"net params #: {num_params}")

    if load_params:
        filename = _get_model_ckpt_file()
        print(f"Load model {filename}")
        checkpoint_state = torch.load(filename, map_location=device)
        epoch = checkpoint_state.get("epoch", 1)
        step = checkpoint_state.get("step", 1)
        print(f"Model checkpoint epoch {epoch}, global train step {step}")

        model_state = checkpoint_state.get("model", checkpoint_state)
        missing_keys_main_ckpt, unexpected_keys_main_ckpt = pt_model.load_state_dict(model_state, strict=False)
        if unexpected_keys_main_ckpt:
            # Note: The model might have been trained with some auxiliary losses (`enc_aux_logits_*.*`)
            # or even an auxiliary decoder (`decoder.*`),
            # and we created the model now without those, so we can get these unexpected keys.
            print(
                f"Note: While loading {filename}, unexpected key(s) in state_dict: "
                + ", ".join(map(repr, sorted(unexpected_keys_main_ckpt))),
            )

    if device:
        pt_model.to(device)
    return model


class Model(rf.Module):
    """Model definition

    This is copied from :class:`i6_experiments.users.zeyer.experiments.exp2024_04_23_baselines.ctc.Model`
    but simplified.
    """

    def __init__(
        self,
        in_dim: Dim,
        *,
        num_enc_layers: int = 12,
        target_dim: Dim,
        wb_target_dim: Optional[Dim] = None,
        blank_idx: int,
        enc_build_dict: Optional[Dict[str, Any]] = None,
        enc_aux_logits: Sequence[int] = (),  # layers, 1-indexed
        enc_model_dim: Dim = Dim(name="enc", dimension=512),
        enc_input_layer: Optional[Dict[str, Any]] = None,
        enc_conformer_layer: Optional[Dict[str, Any]] = None,
        enc_other_opts: Optional[Dict[str, Any]] = None,
    ):
        super(Model, self).__init__()

        self.in_dim = in_dim

        import numpy
        from returnn.config import get_global_config

        config = get_global_config(return_empty_if_none=True)

        if enc_build_dict:
            # Warning: We ignore the other args (num_enc_layers, enc_model_dim, enc_other_opts, etc).
            self.encoder = rf.build_from_dict(enc_build_dict, in_dim)
            self.encoder: ConformerEncoder  # might not be true, but assume similar/same interface

        else:
            if not enc_input_layer:
                enc_input_layer = ConformerConvSubsample(
                    in_dim,
                    out_dims=[Dim(32, name="conv1"), Dim(64, name="conv2"), Dim(64, name="conv3")],
                    filter_sizes=[(3, 3), (3, 3), (3, 3)],
                    pool_sizes=[(1, 2)],
                    strides=[(1, 1), (3, 1), (2, 1)],
                )

            enc_opts = {"input_layer": enc_input_layer, "num_layers": num_enc_layers}

            if enc_conformer_layer:
                enc_opts["encoder_layer"] = enc_conformer_layer

            if enc_other_opts:
                for k, v in enc_other_opts.items():
                    assert k not in enc_opts, f"enc_other_opts key {k!r} already in enc_opts {enc_opts}"
                    enc_opts[k] = v

            self.encoder = ConformerEncoder(in_dim, enc_model_dim, **enc_opts)

        # Experiments without final layer norm. (We might clean this up when this is not successful.)
        # Just patch the encoder here.
        enc_conformer_final_layer_norm = config.typed_value("enc_conformer_final_layer_norm", None)
        if enc_conformer_final_layer_norm is None:
            pass
        elif enc_conformer_final_layer_norm == "last":  # only in the last, i.e. remove everywhere else
            for layer in self.encoder.layers[:-1]:
                layer: ConformerEncoderLayer
                layer.final_layer_norm = rf.identity
        else:
            raise ValueError(f"invalid enc_conformer_final_layer_norm {enc_conformer_final_layer_norm!r}")

        self.target_dim = target_dim
        self.blank_idx = blank_idx

        if not wb_target_dim:
            wb_target_dim = target_dim + 1
        self.enc_aux_selected_layers = enc_aux_logits
        for i in enc_aux_logits:
            setattr(self, f"enc_aux_logits_{i}", rf.Linear(self.encoder.out_dim, wb_target_dim))
        self.enc_logits = rf.Linear(self.encoder.out_dim, wb_target_dim)
        self.wb_target_dim = wb_target_dim
        self.out_blank_separated = config.bool("out_blank_separated", False)
        self.blank_logit_shift = config.float("blank_logit_shift", 0.0)

        self.ctc_am_scale = config.float("ctc_am_scale", 1.0)
        self.ctc_prior_scale = config.float("ctc_prior_scale", 0.0)
        self.ctc_prior_type = config.value("ctc_prior_type", "batch")

        static_prior = config.typed_value("static_prior")
        self.static_prior = None  # in log prob, if set
        if static_prior:
            assert isinstance(static_prior, dict)
            assert set(static_prior.keys()) == {"file", "type"}
            v = numpy.loadtxt(static_prior["file"])
            # The `type` is about what is stored in the file.
            # We always store it in log prob here, so we potentially need to convert it.
            if static_prior["type"] == "log_prob":
                pass  # already log prob
            elif static_prior["type"] == "prob":
                v = numpy.log(v)
            else:
                raise ValueError(f"invalid static_prior type {static_prior['type']!r}")
            self.static_prior = rf.Parameter(
                rf.convert_to_tensor(v, dims=[self.wb_target_dim], dtype=rf.get_default_float_dtype()),
                auxiliary=True,
                non_critical_for_restore=True,
            )

        if target_dim.vocab and not wb_target_dim.vocab:
            # Just assumption for code now, might extend this later.
            assert wb_target_dim.dimension == target_dim.dimension + 1 and blank_idx == target_dim.dimension
            vocab_labels = list(target_dim.vocab.labels) + [output_blank_label]
            wb_target_dim.vocab = Vocabulary.create_vocab_from_labels(
                vocab_labels, user_defined_symbols={output_blank_label: blank_idx}
            )

        ctc_label_smoothing = config.float("ctc_label_smoothing", 0.0)
        ctc_label_smoothing_exclude_blank = config.bool("ctc_label_smoothing_exclude_blank", self.out_blank_separated)
        self.ctc_label_smoothing_exclude_blank = ctc_label_smoothing_exclude_blank
        if not self.out_blank_separated:
            self.ctc_label_smoothing_opts = {
                "smoothing": ctc_label_smoothing,
                "axis": self.wb_target_dim,
                "exclude_labels": [self.blank_idx] if ctc_label_smoothing_exclude_blank else None,
            }
        else:  # separate blank
            self.ctc_label_smoothing_opts = {
                "smoothing": ctc_label_smoothing,
                "axis": self.target_dim if ctc_label_smoothing_exclude_blank else self.wb_target_dim,
            }

        self.feature_batch_norm = None
        if config.bool("feature_batch_norm", False):
            self.feature_batch_norm = rf.BatchNorm(self.in_dim, affine=False, use_mask=True)
        self.feature_norm = config.bool("feature_norm", False)
        self.feature_stats = None
        feature_stats = config.typed_value("feature_stats")
        if feature_stats:
            assert isinstance(feature_stats, dict)
            self.feature_stats = rf.ParameterList(
                {
                    k: rf.Parameter(
                        rf.convert_to_tensor(numpy.loadtxt(v), dims=[self.in_dim], dtype=rf.get_default_float_dtype()),
                        auxiliary=True,
                        non_critical_for_restore=True,
                    )
                    for k, v in feature_stats.items()
                }
            )

        self._specaugment_opts = {
            "steps": config.typed_value("specaugment_steps") or (0, 1000, 2000),
            "max_consecutive_spatial_dims": config.typed_value("specaugment_max_consecutive_spatial_dims") or 20,
            "max_consecutive_feature_dims": config.typed_value("specaugment_max_consecutive_feature_dims")
            or (_log_mel_feature_dim // 5),
            "num_spatial_mask_factor": config.typed_value("specaugment_num_spatial_mask_factor") or 100,
        }

        self.decoder = None
        aux_attention_decoder = config.typed_value("aux_attention_decoder", None)
        if aux_attention_decoder:
            assert isinstance(aux_attention_decoder, dict)
            aux_attention_decoder = aux_attention_decoder.copy()
            aux_attention_decoder.setdefault("class", "returnn.frontend.decoder.transformer.TransformerDecoder")
            if isinstance(aux_attention_decoder.get("model_dim", None), int):
                aux_attention_decoder["model_dim"] = Dim(aux_attention_decoder["model_dim"], name="dec_model")
            self.decoder = rf.build_from_dict(
                aux_attention_decoder, encoder_dim=self.encoder.out_dim, vocab_dim=target_dim
            )

        vn = config.typed_value("variational_noise", None)
        if vn:
            # Use some blacklist. I think the same blacklist as for weight decay is reasonable.
            # Usually sth like: ["rf.Embedding", "rf.LearnedRelativePositionalEncoding"]
            blacklist = config.typed_value("optimizer")["weight_decay_modules_blacklist"]
            blacklist = tuple(eval(name, {"rf": rf}) for name in blacklist)
            for mod in self.modules():
                if isinstance(mod, blacklist):
                    continue
                for param_name, param in mod.named_parameters(recurse=False):
                    if param_name.endswith("bias"):  # no bias
                        continue
                    if param.auxiliary:
                        continue
                    rf.weight_noise(mod, param_name, std=vn)

        weight_dropout = config.typed_value("weight_dropout", None)
        if weight_dropout:
            # Use some blacklist. I think the same blacklist as for weight decay is reasonable.
            # Usually sth like: ["rf.Embedding", "rf.LearnedRelativePositionalEncoding"]
            blacklist = config.typed_value("optimizer")["weight_decay_modules_blacklist"]
            blacklist = tuple(eval(name, {"rf": rf}) for name in blacklist)
            for mod in self.modules():
                if isinstance(mod, blacklist):
                    continue
                for param_name, param in mod.named_parameters(recurse=False):
                    if param_name.endswith("bias"):  # no bias
                        continue
                    if param.auxiliary:
                        continue
                    rf.weight_dropout(mod, param_name, drop_prob=weight_dropout)

    def __call__(
        self,
        source: Tensor,
        *,
        in_spatial_dim: Dim,
        collected_outputs: Optional[Dict[str, Tensor]] = None,
    ) -> Tuple[Tensor, Tensor, Dim]:
        """
        Encode, get CTC logits.
        Use :func:`log_probs_wb_from_logits` to get log probs
        (might be just log_softmax, but there are some other cases).

        :param source: shape {..., in_spatial_dim}, for example {batch_dim, in_spatial_dim}, audio samples, 16khz
        :param in_spatial_dim: input spatial dim
        :param collected_outputs: if provided, will write intermediate encoder outputs into it
        :return: logits, enc, enc_spatial_dim.
            logits shape: {..., enc_spatial_dim, self.wb_target_dim}.
            enc shape: {..., enc_spatial_dim, self.encoder.out_dim}.
            enc_spatial_dim: output spatial dim.
            Use :func:`log_probs_wb_from_logits` on the logits to get log probs
            (which is just :func:`rf.log_softmax` in the standard case).
        """
        # log mel filterbank features
        source, in_spatial_dim = rf.audio.log_mel_filterbank_from_raw(
            source,
            in_spatial_dim=in_spatial_dim,
            out_dim=self.in_dim,
            sampling_rate=16_000,
        )
        if self.feature_batch_norm:
            source = self.feature_batch_norm(source)
        if self.feature_norm:
            source = rf.normalize(source, axis=in_spatial_dim)
        if self.feature_stats:
            source = (source - self.feature_stats.mean) / self.feature_stats.std_dev
        # SpecAugment
        source = rf.audio.specaugment(
            source,
            spatial_dim=in_spatial_dim,
            feature_dim=self.in_dim,
            **self._specaugment_opts,
        )
        # Encoder including convolutional frontend
        enc, enc_spatial_dim = self.encoder(source, in_spatial_dim=in_spatial_dim, collected_outputs=collected_outputs)
        logits = self.enc_logits(enc)
        return logits, enc, enc_spatial_dim

    def aux_logits_from_collected_outputs(self, aux_layer: int, collected_outputs: Dict[str, Tensor]) -> Tensor:
        """
        :param aux_layer:
        :param collected_outputs: from __call__
        :return: logits
        """
        linear: rf.Linear = getattr(self, f"enc_aux_logits_{aux_layer}")
        aux_logits = linear(collected_outputs[str(aux_layer - 1)])
        return aux_logits

    def log_probs_wb_from_logits(self, logits: Tensor) -> Tensor:
        """
        :param logits: incl blank
        :return: log probs with blank from logits (wb_target_dim)
            If out_blank_separated, we use a separate sigmoid for the blank.
            Also, potentially adds label smoothing on the gradients.
        """
        if not self.out_blank_separated:  # standard case, joint distrib incl blank
            if self.blank_logit_shift:
                logits += rf.sparse_to_dense(
                    self.blank_idx, label_value=self.blank_logit_shift, other_value=0, axis=self.wb_target_dim
                )
            log_probs = rf.log_softmax(logits, axis=self.wb_target_dim)
        else:  # separate blank
            assert self.blank_idx == self.target_dim.dimension  # not implemented otherwise
            dummy_blank_feat_dim = Dim(1, name="blank_feat")
            logits_wo_blank, logits_blank = rf.split(
                logits, axis=self.wb_target_dim, out_dims=[self.target_dim, dummy_blank_feat_dim]
            )
            log_probs_wo_blank = rf.log_softmax(logits_wo_blank, axis=self.target_dim)
            log_probs_wo_blank = self._maybe_apply_on_log_probs(log_probs_wo_blank)
            if self.blank_logit_shift:
                logits_blank += self.blank_logit_shift
            log_probs_blank = rf.log_sigmoid(logits_blank)
            log_probs_emit = rf.squeeze(rf.log_sigmoid(-logits_blank), axis=dummy_blank_feat_dim)
            log_probs, _ = rf.concat(
                (log_probs_wo_blank + log_probs_emit, self.target_dim),
                (log_probs_blank, dummy_blank_feat_dim),
                out_dim=self.wb_target_dim,
            )
            log_probs.feature_dim = self.wb_target_dim

        log_probs = self._maybe_apply_on_log_probs(log_probs)
        if self.ctc_am_scale == 1 and self.ctc_prior_scale == 0:  # fast path
            return log_probs
        log_probs_am = log_probs
        log_probs = log_probs_am * self.ctc_am_scale
        if self.ctc_prior_scale:
            if self.ctc_prior_type == "batch":
                # Warning: this is sum, but we want mean!
                log_prob_prior = rf.reduce_logsumexp(
                    log_probs_am, axis=[dim for dim in log_probs_am.dims if dim != self.wb_target_dim]
                )
                assert log_prob_prior.dims == (self.wb_target_dim,)
            elif self.ctc_prior_type == "batch_fixed":
                log_prob_prior = rf.reduce_logmeanexp(
                    log_probs_am, axis=[dim for dim in log_probs_am.dims if dim != self.wb_target_dim]
                )
                assert log_prob_prior.dims == (self.wb_target_dim,)
            elif self.ctc_prior_type == "batch_stop_grad":
                log_prob_prior = rf.stop_gradient(
                    rf.reduce_logmeanexp(
                        log_probs_am, axis=[dim for dim in log_probs_am.dims if dim != self.wb_target_dim]
                    )
                )
                assert log_prob_prior.dims == (self.wb_target_dim,)
            elif self.ctc_prior_type == "static":
                log_prob_prior = self.static_prior
                assert log_prob_prior.dims == (self.wb_target_dim,)
            else:
                raise ValueError(f"invalid ctc_prior_type {self.ctc_prior_type!r}")
            log_probs -= log_prob_prior * self.ctc_prior_scale
        return log_probs

    def _maybe_apply_on_log_probs(self, log_probs: Tensor) -> Tensor:
        """
        :param log_probs: either with blank or without blank
        :return: log probs, maybe some smoothing applied (all on gradients so far, not on log probs itself)
        """
        assert log_probs.feature_dim in (self.wb_target_dim, self.target_dim)
        if not self.out_blank_separated:
            assert log_probs.feature_dim == self.wb_target_dim

        if self.ctc_label_smoothing_exclude_blank:
            if self.out_blank_separated:
                if log_probs.feature_dim == self.target_dim:
                    log_probs = rf.label_smoothed_log_prob_gradient(log_probs, **self.ctc_label_smoothing_opts)
            else:
                assert log_probs.feature_dim == self.wb_target_dim
                assert self.ctc_label_smoothing_opts["exclude_labels"] == [self.blank_idx]
                log_probs = rf.label_smoothed_log_prob_gradient(log_probs, **self.ctc_label_smoothing_opts)
        else:
            if log_probs.feature_dim == self.wb_target_dim:
                log_probs = rf.label_smoothed_log_prob_gradient(log_probs, **self.ctc_label_smoothing_opts)

        return log_probs


if __name__ == "__main__":
    _demo()
