#!rnn.py


accum_grad_multiple_step = 4
backend = "torch"
batch_size = 2400000
batching = "random"
beam_search_opts = {"beam_size": 12}
debug_print_layer_output_template = True
default_input = "data"
device = "gpu"
forward_data = {
    "class": "MetaDataset",
    "data_map": {
        "data": ("zip_dataset", "data"),
        "targets": ("zip_dataset", "classes"),
    },
    "datasets": {
        "zip_dataset": {
            "audio": {
                "features": "raw",
                "peak_normalization": True,
                "pre_process": None,
                "preemphasis": None,
            },
            "class": "OggZipDataset",
            "epoch_wise_filter": None,
            "fixed_random_subset": None,
            "partition_epoch": 1,
            "path": [
                "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/returnn/oggzip/BlissToOggZipJob.NSdIHfk1iw2M/output/out.ogg.zip"
            ],
            "segment_file": None,
            "seq_ordering": "sorted_reverse",
            "targets": {
                "bpe_file": "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/text/label/subword_nmt/train/ReturnnTrainBpeJob.vTq56NZ8STWt/output/bpe.codes",
                "class": "BytePairEncoding",
                "seq_postfix": [0],
                "unknown_label": None,
                "vocab_file": "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/text/label/subword_nmt/train/ReturnnTrainBpeJob.vTq56NZ8STWt/output/bpe.vocab",
            },
            "use_cache_manager": True,
        }
    },
    "seq_order_control_dataset": "zip_dataset",
}

log = ["./returnn.log"]
log_batch_size = True
log_verbosity = 5
max_seqs = 200
non_blank_vocab = {
    "bos_label": 0,
    "bpe_file": "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/text/label/subword_nmt/train/ReturnnTrainBpeJob.vTq56NZ8STWt/output/bpe.codes",
    "eos_label": 0,
    "unknown_label": None,
    "vocab_file": "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/text/label/subword_nmt/train/ReturnnTrainBpeJob.vTq56NZ8STWt/output/bpe.vocab",
}
optimizer = {"class": "adamw", "epsilon": 1e-08, "weight_decay": 1e-06}
search_output_layer = "decision"
target = "targets"
task = "forward"
tf_log_dir = "returnn-tf-log"
torch_dataloader_opts = {"num_workers": 1}
torch_log_memory_usage = True
config = {}

locals().update(**config)

import os
import sys

sys.path.insert(0, "/u/schmitt/experiments/segmental_models_2022_23_rf/recipe")
sys.path.insert(1, "/u/schmitt/src/sisyphus")
from returnn.tensor import Dim, batch_dim, single_step_dim
from returnn.tensor.marked_dim import ImplicitDynSizeDim, ImplicitSparseDim

time_dim = Dim(description="time", dimension=None, kind=Dim.Types.Spatial)
audio_dim = Dim(description="audio", dimension=1, kind=Dim.Types.Feature)
out_spatial_dim = Dim(description="out_spatial", dimension=None, kind=Dim.Types.Spatial)
vocab_dim = Dim(description="vocab", dimension=10026, kind=Dim.Types.Spatial)

extern_data = {
    "data": {"dim_tags": [batch_dim, time_dim, audio_dim]},
    "targets": {"dim_tags": [batch_dim, out_spatial_dim], "sparse_dim": vocab_dim},
}

from i6_experiments.users.schmitt.experiments.config.pipelines.global_vs_segmental_2022_23_rf.dependencies.returnn.network_builder_rf.segmental.luca_example_transducer.transducer_model_luca import (
    from_scratch_model_def as _model_def,
)
from i6_experiments.users.schmitt.experiments.config.pipelines.global_vs_segmental_2022_23_rf.dependencies.returnn.network_builder_rf.segmental.luca_example_transducer.transducer_model_luca import (
    _returnn_v2_get_model as get_model,
)
from i6_experiments.users.schmitt.experiments.config.pipelines.global_vs_segmental_2022_23_rf.dependencies.returnn.network_builder_rf.segmental.recog import (
    model_recog as _recog_def,
)
from i6_experiments.users.schmitt.experiments.config.pipelines.global_vs_segmental_2022_23_rf.dependencies.returnn.network_builder_rf.recog import (
    _returnn_v2_forward_step as forward_step,
)
from i6_experiments.users.schmitt.experiments.config.pipelines.global_vs_segmental_2022_23_rf.dependencies.returnn.network_builder_rf.recog import (
    _returnn_v2_get_forward_callback as forward_callback,
)

# https://github.com/rwth-i6/returnn/issues/957
# https://stackoverflow.com/a/16248113/133374
import resource
import sys

try:
    resource.setrlimit(resource.RLIMIT_STACK, (2**29, -1))
except Exception as exc:
    print(f"resource.setrlimit {type(exc).__name__}: {exc}")
sys.setrecursionlimit(10**6)
_cf_cache = {}


def cf(filename):
    "Cache manager"
    from subprocess import check_output, CalledProcessError

    if filename in _cf_cache:
        return _cf_cache[filename]
    if int(os.environ.get("RETURNN_DEBUG", "0")):
        print("use local file: %s" % filename)
        return filename  # for debugging
    try:
        cached_fn = check_output(["cf", filename]).strip().decode("utf8")
    except CalledProcessError:
        print("Cache manager: Error occurred, using local file")
        return filename
    assert os.path.exists(cached_fn)
    _cf_cache[filename] = cached_fn
    return cached_fn


# -*- mode: python; tab-width: 4 -*-
