#!rnn.py

from i6_experiments.users.gaudino.experiments.rf_conformer_att_2023.librispeech_960.conformer_import_moh_att_2023_06_30 import MakeModel, Model
from i6_experiments.users.gaudino.experiments.rf_conformer_att_2023.librispeech_960.conformer_import_moh_att_2023_06_30 import model_recog

import gzip

from returnn.forward_iface import ForwardCallbackIface

from returnn.tensor import Tensor, Dim, batch_dim, TensorDict
from returnn.datasets.util.vocabulary import Vocabulary
import returnn.frontend as rf

in_dim = Dim(name="in", dimension=80, kind=Dim.Types.Feature)
time_dim = Dim(
    name="time",
    dimension=None,
    kind=Dim.Types.Spatial,
    dyn_size_ext=Tensor("time_size", dims=[batch_dim], dtype="int32"),
)
target_dim = Dim(name="target", dimension=10_025, kind=Dim.Types.Feature)
# target_dim.vocab = Vocabulary.create_vocab_from_labels([str(i) for i in range(target_dim.dimension)], eos_label=0)
target_dim.vocab = Vocabulary("/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/text/label/subword_nmt/train/ReturnnTrainBpeJob.vTq56NZ8STWt/output/bpe.vocab", eos_label=0)
data = Tensor("data", dim_tags=[batch_dim, time_dim, Dim(1, name="dummy-feature")], feature_dim_axis=-1)
target_spatial_dim = Dim(
    name="target_spatial",
    dimension=None,
    kind=Dim.Types.Spatial,
    dyn_size_ext=Tensor("target_spatial_size", dims=[batch_dim], dtype="int32"),
)
target = Tensor("target", dim_tags=[batch_dim, target_spatial_dim], sparse_dim=target_dim)


backend="torch"

batch_size = 2400000
batching = "random"
cleanup_old_models = True
debug_mode = False
debug_print_layer_output_template = True
device = "gpu"

extern_data = {
    "audio_features": {"available_for_inference": True, "shape": (None, 1), "dim": 1},
    "bpe_labels": {
        "available_for_inference": False,
        "shape": (None,),
        "dim": 10025,
        "sparse": True,
    },
}

# extern_data = {
#     "audio_features": {"dim_tags": data.dims, "feature_dim_axis": -1},
#     "bpe_labels": {"dim_tags": target.dims, "sparse_dim": target.sparse_dim},
# }


load = "/work/asr3/zeineldeen/hiwis/luca.gaudino/setups-data/2023-02-22--conformer-swb/work/i6_experiments/users/zeyer/returnn/convert_ckpt_rf/ConvertTfCheckpointToRfPtJob.CWo3NNKEqq5l/output/model/average.pt"
log = ["/u/luca.gaudino/debug/moh_att_import/returnn.log"]
log_batch_size = True
log_verbosity = 5
# max_seq_length = 0
max_seqs = 200


class MyForwardCallback(ForwardCallbackIface):
  def __init__(self):
    self.out_file = None
  def init(self, model):
    self.out_file = open("/u/luca.gaudino/debug/moh_att_import/search_out.py", "w")
    self.out_file.write("{\n")
    # breakpoint()
  def process_seq(self, seq_tag, outputs):
    serialized_target = process_targets(outputs['seq_targets'], outputs['seq_log_prob'])
    output_rep = "'" + serialized_target.replace("'", "\\'") + "'"
    self.out_file.write("%r: %s,\n" % (seq_tag, output_rep))
    # self.out_file.write(repr(seq_tag) + ": [%s],\n" % ...)
  def finish(self):
    self.out_file.write("}\n")
    self.out_file.close()

def process_targets(seq_targets, seq_log_prob):
    max_idx = rf.reduce_argmax(seq_log_prob, axis=seq_log_prob.dims[0])
    b_hyp = rf.gather(seq_targets, indices=max_idx, axis=seq_targets.dims[1])

    b_hyp_np = b_hyp.raw_tensor.cpu().numpy()

    return target_dim.vocab.get_seq_labels(b_hyp_np)


num_layers = 12

def get_model(**_kwargs):
    return MakeModel.make_model(in_dim, target_dim, num_enc_layers=num_layers)


def forward_step(*, model: Model, extern_data: TensorDict, **_kwargs):
    """
    Function used in inference.
    """
    # data = extern_data["data"]
    # out = model(data.raw_tensor)
    # rf.get_run_ctx().mark_as_default_output(tensor=out)

    with rf.set_default_device_ctx("cuda"):
        seq_targets, seq_log_prob, out_spatial_dim, beam_dim = model_recog(
            model=model,
            data=extern_data["audio_features"],
            data_spatial_dim=extern_data["audio_features"].get_time_dim_tag(),
            # data_spatial_dim=time_dim,
            targets_dim=target_dim,
        )


    rf.get_run_ctx().mark_as_output(seq_targets, "seq_targets")
    rf.get_run_ctx().mark_as_output(seq_log_prob, "seq_log_prob")

    # return seq_targets, seq_log_prob, out_spatial_dim, beam_dim

forward_callback = MyForwardCallback()

forward_data = {
    "class": "MetaDataset",
    "data_map": {
        "audio_features": ("zip_dataset", "data"),
        "bpe_labels": ("zip_dataset", "classes"),
    },
    "datasets": {
        "zip_dataset": {
            "class": "OggZipDataset",
            "path": "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/returnn/oggzip/BlissToOggZipJob.NSdIHfk1iw2M/output/out.ogg.zip",
            "use_cache_manager": True,
            "audio": {
                "features": "raw",
                "peak_normalization": True,
                "preemphasis": None,
            },
            "targets": {
                "class": "BytePairEncoding",
                "bpe_file": "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/text/label/subword_nmt/train/ReturnnTrainBpeJob.vTq56NZ8STWt/output/bpe.codes",
                "vocab_file": "/u/zeineldeen/setups/librispeech/2022-11-28--conformer-att/work/i6_core/text/label/subword_nmt/train/ReturnnTrainBpeJob.vTq56NZ8STWt/output/bpe.vocab",
                "unknown_label": "<unk>",
                "seq_postfix": [0],
            },
            "segment_file": None,
            "partition_epoch": 1,
            "seq_ordering": "sorted_reverse",
            # "fixed_random_subset": 30,
        }
    },
    "seq_order_control_dataset": "zip_dataset",
}
search_do_eval = 0
search_output_file = "/u/luca.gaudino/debug/moh_att_import/search_out"
search_output_file_format = "py"
search_output_layer = "decision"
task = "forward"
tf_log_memory_usage = True
truncation = -1
# use_learning_rate_control_always = True
# use_tensorflow = True
config = {}

locals().update(**config)