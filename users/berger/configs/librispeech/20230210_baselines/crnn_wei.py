network = {
    "conformer_10_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_10_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_10_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_10_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_10_conv_mod_dropout": {
        "class": "copy",
        "dropout": 0.1,
        "from": "conformer_10_conv_mod_pointwise_conv_2",
    },
    "conformer_10_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_10_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_10_conv_mod_ln": {"class": "layer_norm", "from": "conformer_10_ffmod_1_half_res_add"},
    "conformer_10_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_10_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_10_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_10_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_10_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_10_conv_mod_dropout", "conformer_10_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_10_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_10_conv_mod_bn"},
    "conformer_10_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_10_ffmod_1_dropout_linear"},
    "conformer_10_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_10_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_10_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_10_ffmod_1_dropout", "conformer_9_output"],
    },
    "conformer_10_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_10_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_10_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_9_output"},
    "conformer_10_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_10_ffmod_2_dropout_linear"},
    "conformer_10_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_10_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_10_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_10_ffmod_2_dropout", "conformer_10_mhsa_mod_res_add"],
    },
    "conformer_10_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_10_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_10_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_10_mhsa_mod_res_add"},
    "conformer_10_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_10_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_10_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_10_mhsa_mod_att_linear"},
    "conformer_10_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_10_conv_mod_res_add"},
    "conformer_10_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_10_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_10_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_10_mhsa_mod_dropout", "conformer_10_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_10_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_10_mhsa_mod_ln",
        "key_shift": "conformer_10_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_10_output": {"class": "layer_norm", "from": "conformer_10_ffmod_2_half_res_add"},
    "conformer_11_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_11_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_11_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_11_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_11_conv_mod_dropout": {
        "class": "copy",
        "dropout": 0.1,
        "from": "conformer_11_conv_mod_pointwise_conv_2",
    },
    "conformer_11_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_11_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_11_conv_mod_ln": {"class": "layer_norm", "from": "conformer_11_ffmod_1_half_res_add"},
    "conformer_11_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_11_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_11_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_11_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_11_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_11_conv_mod_dropout", "conformer_11_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_11_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_11_conv_mod_bn"},
    "conformer_11_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_11_ffmod_1_dropout_linear"},
    "conformer_11_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_11_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_11_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_11_ffmod_1_dropout", "conformer_10_output"],
    },
    "conformer_11_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_11_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_11_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_10_output"},
    "conformer_11_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_11_ffmod_2_dropout_linear"},
    "conformer_11_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_11_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_11_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_11_ffmod_2_dropout", "conformer_11_mhsa_mod_res_add"],
    },
    "conformer_11_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_11_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_11_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_11_mhsa_mod_res_add"},
    "conformer_11_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_11_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_11_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_11_mhsa_mod_att_linear"},
    "conformer_11_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_11_conv_mod_res_add"},
    "conformer_11_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_11_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_11_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_11_mhsa_mod_dropout", "conformer_11_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_11_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_11_mhsa_mod_ln",
        "key_shift": "conformer_11_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_11_output": {"class": "layer_norm", "from": "conformer_11_ffmod_2_half_res_add"},
    "conformer_12_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_12_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_12_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_12_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_12_conv_mod_dropout": {
        "class": "copy",
        "dropout": 0.1,
        "from": "conformer_12_conv_mod_pointwise_conv_2",
    },
    "conformer_12_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_12_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_12_conv_mod_ln": {"class": "layer_norm", "from": "conformer_12_ffmod_1_half_res_add"},
    "conformer_12_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_12_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_12_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_12_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_12_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_12_conv_mod_dropout", "conformer_12_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_12_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_12_conv_mod_bn"},
    "conformer_12_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_12_ffmod_1_dropout_linear"},
    "conformer_12_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_12_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_12_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_12_ffmod_1_dropout", "conformer_11_output"],
    },
    "conformer_12_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_12_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_12_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_11_output"},
    "conformer_12_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_12_ffmod_2_dropout_linear"},
    "conformer_12_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_12_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_12_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_12_ffmod_2_dropout", "conformer_12_mhsa_mod_res_add"],
    },
    "conformer_12_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_12_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_12_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_12_mhsa_mod_res_add"},
    "conformer_12_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_12_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_12_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_12_mhsa_mod_att_linear"},
    "conformer_12_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_12_conv_mod_res_add"},
    "conformer_12_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_12_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_12_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_12_mhsa_mod_dropout", "conformer_12_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_12_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_12_mhsa_mod_ln",
        "key_shift": "conformer_12_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_12_output": {"class": "layer_norm", "from": "conformer_12_ffmod_2_half_res_add"},
    "conformer_1_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_1_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_1_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_1_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_1_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_1_conv_mod_pointwise_conv_2"},
    "conformer_1_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_1_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_1_conv_mod_ln": {"class": "layer_norm", "from": "conformer_1_ffmod_1_half_res_add"},
    "conformer_1_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_1_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_1_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_1_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_1_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_1_conv_mod_dropout", "conformer_1_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_1_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_1_conv_mod_bn"},
    "conformer_1_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_1_ffmod_1_dropout_linear"},
    "conformer_1_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_1_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_1_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_1_ffmod_1_dropout", "input_dropout"],
    },
    "conformer_1_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_1_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_1_ffmod_1_ln": {"class": "layer_norm", "from": "input_dropout"},
    "conformer_1_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_1_ffmod_2_dropout_linear"},
    "conformer_1_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_1_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_1_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_1_ffmod_2_dropout", "conformer_1_mhsa_mod_res_add"],
    },
    "conformer_1_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_1_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_1_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_1_mhsa_mod_res_add"},
    "conformer_1_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_1_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_1_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_1_mhsa_mod_att_linear"},
    "conformer_1_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_1_conv_mod_res_add"},
    "conformer_1_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_1_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_1_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_1_mhsa_mod_dropout", "conformer_1_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_1_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_1_mhsa_mod_ln",
        "key_shift": "conformer_1_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_1_output": {"class": "layer_norm", "from": "conformer_1_ffmod_2_half_res_add"},
    "conformer_2_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_2_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_2_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_2_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_2_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_2_conv_mod_pointwise_conv_2"},
    "conformer_2_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_2_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_2_conv_mod_ln": {"class": "layer_norm", "from": "conformer_2_ffmod_1_half_res_add"},
    "conformer_2_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_2_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_2_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_2_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_2_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_2_conv_mod_dropout", "conformer_2_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_2_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_2_conv_mod_bn"},
    "conformer_2_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_2_ffmod_1_dropout_linear"},
    "conformer_2_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_2_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_2_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_2_ffmod_1_dropout", "conformer_1_output"],
    },
    "conformer_2_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_2_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_2_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_1_output"},
    "conformer_2_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_2_ffmod_2_dropout_linear"},
    "conformer_2_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_2_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_2_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_2_ffmod_2_dropout", "conformer_2_mhsa_mod_res_add"],
    },
    "conformer_2_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_2_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_2_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_2_mhsa_mod_res_add"},
    "conformer_2_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_2_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_2_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_2_mhsa_mod_att_linear"},
    "conformer_2_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_2_conv_mod_res_add"},
    "conformer_2_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_2_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_2_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_2_mhsa_mod_dropout", "conformer_2_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_2_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_2_mhsa_mod_ln",
        "key_shift": "conformer_2_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_2_output": {"class": "layer_norm", "from": "conformer_2_ffmod_2_half_res_add"},
    "conformer_3_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_3_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_3_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_3_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_3_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_3_conv_mod_pointwise_conv_2"},
    "conformer_3_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_3_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_3_conv_mod_ln": {"class": "layer_norm", "from": "conformer_3_ffmod_1_half_res_add"},
    "conformer_3_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_3_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_3_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_3_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_3_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_3_conv_mod_dropout", "conformer_3_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_3_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_3_conv_mod_bn"},
    "conformer_3_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_3_ffmod_1_dropout_linear"},
    "conformer_3_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_3_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_3_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_3_ffmod_1_dropout", "conformer_2_output"],
    },
    "conformer_3_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_3_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_3_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_2_output"},
    "conformer_3_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_3_ffmod_2_dropout_linear"},
    "conformer_3_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_3_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_3_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_3_ffmod_2_dropout", "conformer_3_mhsa_mod_res_add"],
    },
    "conformer_3_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_3_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_3_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_3_mhsa_mod_res_add"},
    "conformer_3_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_3_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_3_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_3_mhsa_mod_att_linear"},
    "conformer_3_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_3_conv_mod_res_add"},
    "conformer_3_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_3_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_3_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_3_mhsa_mod_dropout", "conformer_3_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_3_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_3_mhsa_mod_ln",
        "key_shift": "conformer_3_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_3_output": {"class": "layer_norm", "from": "conformer_3_ffmod_2_half_res_add"},
    "conformer_4_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_4_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_4_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_4_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_4_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_4_conv_mod_pointwise_conv_2"},
    "conformer_4_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_4_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_4_conv_mod_ln": {"class": "layer_norm", "from": "conformer_4_ffmod_1_half_res_add"},
    "conformer_4_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_4_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_4_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_4_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_4_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_4_conv_mod_dropout", "conformer_4_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_4_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_4_conv_mod_bn"},
    "conformer_4_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_4_ffmod_1_dropout_linear"},
    "conformer_4_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_4_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_4_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_4_ffmod_1_dropout", "conformer_3_output"],
    },
    "conformer_4_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_4_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_4_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_3_output"},
    "conformer_4_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_4_ffmod_2_dropout_linear"},
    "conformer_4_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_4_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_4_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_4_ffmod_2_dropout", "conformer_4_mhsa_mod_res_add"],
    },
    "conformer_4_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_4_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_4_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_4_mhsa_mod_res_add"},
    "conformer_4_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_4_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_4_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_4_mhsa_mod_att_linear"},
    "conformer_4_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_4_conv_mod_res_add"},
    "conformer_4_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_4_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_4_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_4_mhsa_mod_dropout", "conformer_4_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_4_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_4_mhsa_mod_ln",
        "key_shift": "conformer_4_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_4_output": {"class": "layer_norm", "from": "conformer_4_ffmod_2_half_res_add"},
    "conformer_5_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_5_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_5_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_5_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_5_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_5_conv_mod_pointwise_conv_2"},
    "conformer_5_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_5_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_5_conv_mod_ln": {"class": "layer_norm", "from": "conformer_5_ffmod_1_half_res_add"},
    "conformer_5_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_5_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_5_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_5_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_5_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_5_conv_mod_dropout", "conformer_5_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_5_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_5_conv_mod_bn"},
    "conformer_5_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_5_ffmod_1_dropout_linear"},
    "conformer_5_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_5_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_5_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_5_ffmod_1_dropout", "conformer_4_output"],
    },
    "conformer_5_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_5_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_5_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_4_output"},
    "conformer_5_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_5_ffmod_2_dropout_linear"},
    "conformer_5_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_5_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_5_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_5_ffmod_2_dropout", "conformer_5_mhsa_mod_res_add"],
    },
    "conformer_5_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_5_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_5_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_5_mhsa_mod_res_add"},
    "conformer_5_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_5_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_5_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_5_mhsa_mod_att_linear"},
    "conformer_5_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_5_conv_mod_res_add"},
    "conformer_5_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_5_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_5_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_5_mhsa_mod_dropout", "conformer_5_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_5_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_5_mhsa_mod_ln",
        "key_shift": "conformer_5_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_5_output": {"class": "layer_norm", "from": "conformer_5_ffmod_2_half_res_add"},
    "conformer_6_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_6_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_6_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_6_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_6_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_6_conv_mod_pointwise_conv_2"},
    "conformer_6_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_6_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_6_conv_mod_ln": {"class": "layer_norm", "from": "conformer_6_ffmod_1_half_res_add"},
    "conformer_6_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_6_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_6_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_6_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_6_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_6_conv_mod_dropout", "conformer_6_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_6_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_6_conv_mod_bn"},
    "conformer_6_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_6_ffmod_1_dropout_linear"},
    "conformer_6_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_6_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_6_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_6_ffmod_1_dropout", "conformer_5_output"],
    },
    "conformer_6_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_6_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_6_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_5_output"},
    "conformer_6_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_6_ffmod_2_dropout_linear"},
    "conformer_6_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_6_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_6_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_6_ffmod_2_dropout", "conformer_6_mhsa_mod_res_add"],
    },
    "conformer_6_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_6_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_6_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_6_mhsa_mod_res_add"},
    "conformer_6_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_6_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_6_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_6_mhsa_mod_att_linear"},
    "conformer_6_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_6_conv_mod_res_add"},
    "conformer_6_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_6_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_6_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_6_mhsa_mod_dropout", "conformer_6_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_6_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_6_mhsa_mod_ln",
        "key_shift": "conformer_6_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_6_output": {"class": "layer_norm", "from": "conformer_6_ffmod_2_half_res_add"},
    "conformer_7_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_7_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_7_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_7_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_7_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_7_conv_mod_pointwise_conv_2"},
    "conformer_7_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_7_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_7_conv_mod_ln": {"class": "layer_norm", "from": "conformer_7_ffmod_1_half_res_add"},
    "conformer_7_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_7_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_7_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_7_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_7_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_7_conv_mod_dropout", "conformer_7_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_7_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_7_conv_mod_bn"},
    "conformer_7_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_7_ffmod_1_dropout_linear"},
    "conformer_7_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_7_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_7_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_7_ffmod_1_dropout", "conformer_6_output"],
    },
    "conformer_7_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_7_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_7_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_6_output"},
    "conformer_7_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_7_ffmod_2_dropout_linear"},
    "conformer_7_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_7_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_7_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_7_ffmod_2_dropout", "conformer_7_mhsa_mod_res_add"],
    },
    "conformer_7_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_7_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_7_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_7_mhsa_mod_res_add"},
    "conformer_7_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_7_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_7_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_7_mhsa_mod_att_linear"},
    "conformer_7_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_7_conv_mod_res_add"},
    "conformer_7_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_7_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_7_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_7_mhsa_mod_dropout", "conformer_7_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_7_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_7_mhsa_mod_ln",
        "key_shift": "conformer_7_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_7_output": {"class": "layer_norm", "from": "conformer_7_ffmod_2_half_res_add"},
    "conformer_8_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_8_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_8_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_8_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_8_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_8_conv_mod_pointwise_conv_2"},
    "conformer_8_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_8_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_8_conv_mod_ln": {"class": "layer_norm", "from": "conformer_8_ffmod_1_half_res_add"},
    "conformer_8_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_8_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_8_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_8_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_8_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_8_conv_mod_dropout", "conformer_8_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_8_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_8_conv_mod_bn"},
    "conformer_8_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_8_ffmod_1_dropout_linear"},
    "conformer_8_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_8_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_8_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_8_ffmod_1_dropout", "conformer_7_output"],
    },
    "conformer_8_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_8_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_8_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_7_output"},
    "conformer_8_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_8_ffmod_2_dropout_linear"},
    "conformer_8_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_8_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_8_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_8_ffmod_2_dropout", "conformer_8_mhsa_mod_res_add"],
    },
    "conformer_8_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_8_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_8_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_8_mhsa_mod_res_add"},
    "conformer_8_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_8_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_8_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_8_mhsa_mod_att_linear"},
    "conformer_8_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_8_conv_mod_res_add"},
    "conformer_8_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_8_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_8_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_8_mhsa_mod_dropout", "conformer_8_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_8_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_8_mhsa_mod_ln",
        "key_shift": "conformer_8_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_8_output": {"class": "layer_norm", "from": "conformer_8_ffmod_2_half_res_add"},
    "conformer_9_conv_mod_bn": {
        "class": "batch_norm",
        "delay_sample_update": True,
        "epsilon": 1e-05,
        "from": "conformer_9_conv_mod_depthwise_conv",
        "momentum": 0.1,
        "update_sample_only_in_training": True,
    },
    "conformer_9_conv_mod_depthwise_conv": {
        "L2": 5e-06,
        "activation": None,
        "class": "conv",
        "filter_size": (32,),
        "from": "conformer_9_conv_mod_glu",
        "groups": 512,
        "n_out": 512,
        "padding": "same",
        "with_bias": True,
    },
    "conformer_9_conv_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_9_conv_mod_pointwise_conv_2"},
    "conformer_9_conv_mod_glu": {
        "activation": None,
        "class": "gating",
        "from": "conformer_9_conv_mod_pointwise_conv_1",
        "gate_activation": "sigmoid",
    },
    "conformer_9_conv_mod_ln": {"class": "layer_norm", "from": "conformer_9_ffmod_1_half_res_add"},
    "conformer_9_conv_mod_pointwise_conv_1": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_9_conv_mod_ln",
        "n_out": 1024,
    },
    "conformer_9_conv_mod_pointwise_conv_2": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_9_conv_mod_swish",
        "n_out": 512,
    },
    "conformer_9_conv_mod_res_add": {
        "class": "combine",
        "from": ["conformer_9_conv_mod_dropout", "conformer_9_ffmod_1_half_res_add"],
        "kind": "add",
    },
    "conformer_9_conv_mod_swish": {"activation": "swish", "class": "activation", "from": "conformer_9_conv_mod_bn"},
    "conformer_9_ffmod_1_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_9_ffmod_1_dropout_linear"},
    "conformer_9_ffmod_1_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_9_ffmod_1_linear_swish",
        "n_out": 512,
    },
    "conformer_9_ffmod_1_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_9_ffmod_1_dropout", "conformer_8_output"],
    },
    "conformer_9_ffmod_1_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_9_ffmod_1_ln",
        "n_out": 2048,
    },
    "conformer_9_ffmod_1_ln": {"class": "layer_norm", "from": "conformer_8_output"},
    "conformer_9_ffmod_2_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_9_ffmod_2_dropout_linear"},
    "conformer_9_ffmod_2_dropout_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "dropout": 0.1,
        "from": "conformer_9_ffmod_2_linear_swish",
        "n_out": 512,
    },
    "conformer_9_ffmod_2_half_res_add": {
        "class": "eval",
        "eval": "0.5 * source(0) + source(1)",
        "from": ["conformer_9_ffmod_2_dropout", "conformer_9_mhsa_mod_res_add"],
    },
    "conformer_9_ffmod_2_linear_swish": {
        "L2": 5e-06,
        "activation": "swish",
        "class": "linear",
        "from": "conformer_9_ffmod_2_ln",
        "n_out": 2048,
    },
    "conformer_9_ffmod_2_ln": {"class": "layer_norm", "from": "conformer_9_mhsa_mod_res_add"},
    "conformer_9_mhsa_mod_att_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conformer_9_mhsa_mod_self_attention",
        "n_out": 512,
        "with_bias": False,
    },
    "conformer_9_mhsa_mod_dropout": {"class": "copy", "dropout": 0.1, "from": "conformer_9_mhsa_mod_att_linear"},
    "conformer_9_mhsa_mod_ln": {"class": "layer_norm", "from": "conformer_9_conv_mod_res_add"},
    "conformer_9_mhsa_mod_relpos_encoding": {
        "class": "relative_positional_encoding",
        "clipping": 32,
        "from": "conformer_9_mhsa_mod_ln",
        "n_out": 64,
    },
    "conformer_9_mhsa_mod_res_add": {
        "class": "combine",
        "from": ["conformer_9_mhsa_mod_dropout", "conformer_9_conv_mod_res_add"],
        "kind": "add",
    },
    "conformer_9_mhsa_mod_self_attention": {
        "attention_dropout": 0.1,
        "class": "self_attention",
        "from": "conformer_9_mhsa_mod_ln",
        "key_shift": "conformer_9_mhsa_mod_relpos_encoding",
        "n_out": 512,
        "num_heads": 8,
        "total_key_dim": 512,
    },
    "conformer_9_output": {"class": "layer_norm", "from": "conformer_9_ffmod_2_half_res_add"},
    "conv_1": {
        "L2": 0.01,
        "activation": "swish",
        "class": "conv",
        "filter_size": (3, 3),
        "from": "conv_source",
        "n_out": 32,
        "padding": "same",
        "with_bias": True,
    },
    "conv_1_pool": {
        "class": "pool",
        "from": "conv_1",
        "mode": "max",
        "padding": "same",
        "pool_size": (1, 2),
        "trainable": False,
    },
    "conv_2": {
        "L2": 0.01,
        "activation": "swish",
        "class": "conv",
        "filter_size": (3, 3),
        "from": "conv_1_pool",
        "n_out": 64,
        "padding": "same",
        "strides": (2, 1),
        "with_bias": True,
    },
    "conv_3": {
        "L2": 0.01,
        "activation": "swish",
        "class": "conv",
        "filter_size": (3, 3),
        "from": "conv_2",
        "n_out": 64,
        "padding": "same",
        "strides": (2, 1),
        "with_bias": True,
    },
    "conv_merged": {"axes": "static", "class": "merge_dims", "from": "conv_3"},
    "conv_source": {"axis": "F", "class": "split_dims", "dims": (-1, 1), "from": "source"},
    "enc_output": {"class": "softmax", "from": "encoder", "loss": "ce", "loss_opts": {"focal_loss_factor": 1.0}},
    "enc_output_loss": {
        "class": "softmax",
        "from": "conformer_6_output",
        "loss": "ce",
        "loss_opts": {"focal_loss_factor": 1.0},
        "loss_scale": 0.3,
    },
    "encoder": {"class": "reinterpret_data", "from": "conformer_12_output", "size_base": "data:classes"},
    "input_dropout": {"class": "copy", "dropout": 0.1, "from": "input_linear"},
    "input_linear": {
        "L2": 5e-06,
        "activation": None,
        "class": "linear",
        "from": "conv_merged",
        "n_out": 512,
        "with_bias": False,
    },
    "mask_flag": {"class": "compare", "from": ["data:classes"], "kind": "not_equal", "value": 0},
    "mask_label": {
        "class": "masked_computation",
        "from": ["data:classes"],
        "mask": "mask_flag",
        "unit": {"class": "copy"},
    },
    "output": {
        "cheating": False,
        "class": "rec",
        "from": "encoder",
        "target": "classes",
        "unit": {
            "embedding": {
                "L2": 5e-06,
                "activation": None,
                "class": "linear",
                "from": "base:mask_label",
                "n_out": 128,
                "with_bias": False,
            },
            "joint_encoding": {
                "L2": 5e-06,
                "activation": "tanh",
                "class": "linear",
                "dropout": 0.1,
                "from": ["data:source", "unmask_context_reinterpret"],
                "n_out": 1024,
            },
            "label_lm_1": {
                "L2": 5e-06,
                "activation": "tanh",
                "class": "linear",
                "dropout": 0.1,
                "from": ["mask_embedding"],
                "n_out": 640,
            },
            "label_lm_2": {
                "L2": 5e-06,
                "activation": "tanh",
                "class": "linear",
                "dropout": 0.1,
                "from": "label_lm_1",
                "n_out": 640,
            },
            "mask_embedding": {
                "axes": "T",
                "class": "pad",
                "from": "embedding",
                "mode": "constant",
                "padding": (1, 0),
                "value": 0,
            },
            "mask_flag": {"amount": 1, "axis": "T", "class": "shift_axis", "from": "base:mask_flag", "pad": True},
            "output": {"class": "softmax", "from": "joint_encoding", "loss": "ce"},
            "unmask_context": {"class": "unmask", "from": "label_lm_2", "mask": "mask_flag", "skip_initial": True},
            "unmask_context_reinterpret": {
                "class": "reinterpret_data",
                "from": "unmask_context",
                "size_base": "data:classes",
            },
        },
    },
    "source": {
        "class": "eval",
        "eval": "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)",
    },
}


def summary(name, x):
    """
    :param str name:
    :param tf.Tensor x: (batch,time,feature)
    """
    import tensorflow as tf

    # tf.summary.image wants [batch_size, height,  width, channels],
    # we have (batch, time, feature).
    img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
    img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
    tf.summary.image(name, img, max_outputs=10)
    tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
    mean = tf.reduce_mean(x)
    tf.summary.scalar("%s_mean" % name, mean)
    stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
    tf.summary.scalar("%s_stddev" % name, stddev)
    tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))


def _mask(x, batch_axis, axis, pos, max_amount):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param tf.Tensor pos: (batch,)
    :param int|tf.Tensor max_amount: inclusive
    """
    import tensorflow as tf

    ndim = x.get_shape().ndims
    n_batch = tf.shape(x)[batch_axis]
    dim = tf.shape(x)[axis]
    amount = tf.random.uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
    pos2 = tf.math.minimum(pos + amount, dim)
    idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
    pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
    pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
    cond = tf.math.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
    if batch_axis > axis:
        cond = tf.transpose(cond)  # (dim,batch)
    cond = tf.reshape(cond, [tf.shape(x)[i] if i in (batch_axis, axis) else 1 for i in range(ndim)])
    from TFUtil import where_bc

    x = where_bc(cond, 0.0, x)
    return x


def random_mask(x, batch_axis, axis, min_num, max_num, max_dims):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param int|tf.Tensor min_num:
    :param int|tf.Tensor max_num: inclusive
    :param int|tf.Tensor max_dims: inclusive
    """
    import tensorflow as tf

    n_batch = tf.shape(x)[batch_axis]
    if isinstance(min_num, int) and isinstance(max_num, int) and min_num == max_num:
        num = min_num
    else:
        num = tf.random.uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
    # https://github.com/tensorflow/tensorflow/issues/9260
    # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
    z = -tf.math.log(-tf.math.log(tf.random.uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
    _, indices = tf.math.top_k(z, num if isinstance(num, int) else tf.reduce_max(num))
    # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
    # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
    if isinstance(num, int):
        for i in range(num):
            x = _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims)
    else:
        _, x = tf.while_loop(
            cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
            body=lambda i, x: (
                i + 1,
                tf.where(
                    tf.expand_dims(tf.expand_dims(tf.less(i, num), axis=-1), axis=-1),
                    _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims),
                    x,
                ),
            ),
            loop_vars=(0, x),
        )
    return x


def transform(data, network):
    # to be adjusted (20-50%)
    max_time_num = 1
    max_time = 15

    max_feature_num = 5
    max_feature = 5

    # halved before this step
    conservatvie_step = 2000

    x = data.placeholder
    import tensorflow as tf

    # summary("features", x)
    step = network.global_train_step
    increase_flag = tf.where(tf.greater_equal(step, conservatvie_step), 0, 1)

    def get_masked():
        x_masked = x
        x_masked = random_mask(
            x_masked,
            batch_axis=data.batch_dim_axis,
            axis=data.time_dim_axis,
            min_num=0,
            max_num=tf.maximum(tf.shape(x)[data.time_dim_axis] // int(1 / 0.70 * max_time), max_time_num)
            // (1 + increase_flag),
            max_dims=max_time,
        )
        x_masked = random_mask(
            x_masked,
            batch_axis=data.batch_dim_axis,
            axis=data.feature_dim_axis,
            min_num=0,
            max_num=max_feature_num // (1 + increase_flag),
            max_dims=max_feature,
        )
        # summary("features_mask", x_masked)
        return x_masked

    x = network.cond_on_train(get_masked, lambda: x)
    return x


# one cycle LR: triangular linear w.r.t. iterations(steps)
def dynamic_learning_rate(*, network, global_train_step, learning_rate, **kwargs):
    # -- need to be adjusted w.r.t. training -- #
    initialLR = 8e-5
    peakLR = 8e-4
    finalLR = 1e-6
    cycleEpoch = 180
    totalEpoch = 400
    nStep = 2440  # steps/epoch depending on batch_size

    # -- derived -- #
    steps = cycleEpoch * nStep
    stepSize = (peakLR - initialLR) / steps
    steps2 = (totalEpoch - 2 * cycleEpoch) * nStep
    stepSize2 = (initialLR - finalLR) / steps2

    import tensorflow as tf

    n = tf.cast(global_train_step, tf.float32)
    return tf.where(
        global_train_step <= steps,
        initialLR + stepSize * n,
        tf.where(
            global_train_step <= 2 * steps,
            peakLR - stepSize * (n - steps),
            tf.maximum(initialLR - stepSize2 * (n - 2 * steps), finalLR),
        ),
    )


extra_python = [summary, _mask, random_mask, transform, dynamic_learning_rate]
