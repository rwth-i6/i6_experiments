[*]
configuration.channel    = output-channel
dot.channel              = nil
encoding                 = UTF-8
error.channel            = output-channel, stderr
log.channel              = output-channel
progress.channel         = output-channel
# python-home              = /u/kitza/software/syspy2-tfselfcompile
# python-program-name      = /u/kitza/software/syspy2-tfselfcompile/bin/python2
real-time-factor.channel = output-channel
statistics.channel       = output-channel
system-info.channel      = output-channel
time.channel             = output-channel
version.channel          = output-channel
warning.channel          = output-channel, stderr

[*.output-channel]
append     = no
compressed = no
file       = $(LOGFILE)
unbuffered = yes

[neural-network-trainer]
action                                             = supervised-training
aligning-feature-extractor.feature-extraction.file = /u/berger/asr-exps/librispeech/20230210_baselines/config/extern_sprint_data/train.feature.flow
buffer-size                                        = 204800
buffer-type                                        = utterance
class-labels.save-to-file                          = class.labels
estimator                                          = steepest-descent
feature-extraction.file                            = /u/berger/asr-exps/librispeech/20230210_baselines/config/extern_sprint_data/dummy.flow
regression-window-size                             = 5
shuffle                                            = no
silence-weight                                     = 1.0
single-precision                                   = yes
trainer-output-dimension                           = 79
training-criterion                                 = cross-entropy
weighted-alignment                                 = no
window-size                                        = 1
window-size-derivatives                            = 0

[neural-network-trainer.*]
peak-position           = 1.0
peaky-alignment         = yes
reduce-alignment-factor = 4

[neural-network-trainer.corpus]
audio-dir                      = /
capitalize-transcriptions      = no
file                           = /work/asr4/zhou/data/librispeech/am-data/corpus/train-merged-960.corpus.xml
progress-indication            = global
segments.file                  = /work/asr4/zhou/asr-exps/librispeech/2021-01-22_phoneme-transducer/work/corpus/SegmentCorpus.CqOd3k1v3PIz/output/segments.$(TASK)
warn-about-unexpected-elements = yes

[neural-network-trainer.model-combination.acoustic-model]
state-tying.type = monophone-eow

[neural-network-trainer.model-combination.acoustic-model.allophones]
add-all          = yes
add-from-file    = /work/asr4/zhou/asr-exps/librispeech/2021-01-22_phoneme-transducer/work/allophones/StoreAllophones.88co8MfuJDDS/output/allophones
add-from-lexicon = no

[neural-network-trainer.model-combination.acoustic-model.hmm]
across-word-model   = yes
early-recombination = no
state-repetitions   = 1
states-per-phone    = 1

[neural-network-trainer.model-combination.acoustic-model.phonology]
future-length  = 0
history-length = 0

[neural-network-trainer.model-combination.acoustic-model.tdp]
entry-m1.loop = infinity
entry-m2.loop = infinity
scale         = 1.0

[neural-network-trainer.model-combination.acoustic-model.tdp.*]
exit    = 0
forward = 0
loop    = 0
skip    = 0

[neural-network-trainer.model-combination.acoustic-model.tdp.silence]
exit    = 0
forward = 0
loop    = 0
skip    = 0

[neural-network-trainer.model-combination.lexicon]
file                    = /work/asr4/zhou/data/librispeech/am-data/lexicon/no-stress/lexicon.xml
normalize-pronunciation = no
